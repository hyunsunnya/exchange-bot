import requests
from bs4 import BeautifulSoup
import os
import warnings

warnings.filterwarnings("ignore")

TOKEN = os.environ.get('TELEGRAM_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')

def send_telegram_message(text):
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "Markdown",
        "disable_web_page_preview": True
    }
    try:
        res = requests.post(url, json=payload, timeout=10)
        return res.json()
    except Exception as e:
        print(f"âŒ ì „ì†¡ ì—ëŸ¬: {e}")
        return None

def get_interpark_announcements():
    """ì¸í„°íŒŒí¬ í‹°ì¼“ ì˜¤í”ˆ ê³µì§€ë§Œ ì •í™•í•˜ê²Œ ìˆ˜ì§‘"""
    # ì¿¼ë¦¬: ì¸í„°íŒŒí¬ ì‚¬ì´íŠ¸ ë‚´ì—ì„œ 'í‹°ì¼“ ì˜¤í”ˆ ê³µì§€'ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ìµœì‹  ê²°ê³¼
    query = "site:ticket.interpark.com/Ticket/Goods/TPGoodsGate.asp \"í‹°ì¼“ì˜¤í”ˆê³µì§€\""
    url = f"https://news.google.com/rss/search?q={query}&hl=ko&gl=KR&ceid=KR:ko"
    
    events = []
    headers = {'User-Agent': 'Mozilla/5.0'}

    try:
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        items = soup.find_all('item')

        print(f"ğŸ” ì¸í„°íŒŒí¬ ê³µì§€ ê²€ìƒ‰ ì¤‘... {len(items)}ê±´ ë°œê²¬")

        for item in items[:5]: # ìµœì‹  ê³µì§€ 5ê°œ
            title = item.title.text
            # ì œëª©ì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì •ë¦¬
            clean_title = title.replace(" - ì¸í„°íŒŒí¬", "").replace("í‹°ì¼“ì˜¤í”ˆê³µì§€", "").strip()
            link = item.find('link').next_element.strip()
            
            # ì‹¤ì œ 'ë†€ ì¸í„°íŒŒí¬'ë¡œ ì—°ê²°ë˜ë„ë¡ ë§í¬ í˜•íƒœ ì‚´ì§ ë³€ê²½ (ì„ íƒ ì‚¬í•­)
            # ê¸°ë³¸ ë§í¬ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ë„ ì¸í„°íŒŒí¬ í˜ì´ì§€ë¡œ ì—°ê²°ë©ë‹ˆë‹¤.
            events.append(f"ğŸ“£ **[ì¸í„°íŒŒí¬ ê³µì§€]**\n{clean_title}\nğŸ”— [ê³µì§€í™•ì¸]({link})")
            
    except Exception as e:
        print(f"âŒ ì¸í„°íŒŒí¬ ìˆ˜ì§‘ ì—ëŸ¬: {e}")
    
    return events

if __name__ == "__main__":
    if not TOKEN or not CHAT_ID:
        print("âŒ ì„¤ì • ì—ëŸ¬: GitHub Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        print("ğŸš€ ì¸í„°íŒŒí¬ ê³µì§€ì‚¬í•­ ì¶”ì  ì‹œì‘...")
        
        # ì¸í„°íŒŒí¬ ê³µì§€ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°
        interpark_announcements = get_interpark_announcements()
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ë„ˆë¬´ ì ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì¼ë°˜ ë‰´ìŠ¤ë„ ë³´ê°•
        news_list = []
        try:
            news_query = "í‹°ì¼“ ì˜¤í”ˆ ì½˜ì„œíŠ¸ ë®¤ì§€ì»¬"
            news_url = f"https://news.google.com/rss/search?q={news_query}&hl=ko&gl=KR&ceid=KR:ko"
            res = requests.get(news_url, timeout=10)
            soup = BeautifulSoup(res.content, 'html.parser')
            for item in soup.find_all('item')[:3]:
                news_list.append(f"ğŸ“° **[ë‰´ìŠ¤] {item.title.text.split(' - ')[0]}**\nğŸ”— [ë‰´ìŠ¤ë³´ê¸°]({item.find('link').next_element.strip()})")
        except: pass

        all_messages = interpark_announcements + news_list
        
        if all_messages:
            final_msg = "ğŸ“… **ì˜¤ëŠ˜ì˜ í‹°ì¼“ ì˜¤í”ˆ ì •ë³´**\n"
            final_msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
            final_msg += "\n\n".join(all_messages)
            
            send_telegram_message(final_msg)
            print(f"âœ… ì´ {len(all_messages)}ê±´ ì „ì†¡ ì„±ê³µ!")
        else:
            print("âœ… ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
